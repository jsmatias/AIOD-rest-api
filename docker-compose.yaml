services:
  app:
    build:
      context: ./
      dockerfile: Dockerfile
    image: aiod_metadata_catalogue
    container_name: apiserver
    volumes:
      - ./src/config.override.toml:/app/config.override.toml:ro
    environment:
      - KEYCLOAK_CLIENT_SECRET=$KEYCLOAK_CLIENT_SECRET
      - ES_USER=$ES_USER
      - ES_PASSWORD=$ES_PASSWORD
    ports:
      - ${AIOD_REST_PORT}:8000
    command: >
      python main.py
      --build-db if-absent
    healthcheck:
      test: ["CMD", "python", "-c",  "import requests; requests.get('http://localhost:8000')"]
      start_interval: 1s
      start_period: 30s
      interval: 5s
      timeout: 120s
      retries: 24
    depends_on:
      sqlserver:
        condition: service_healthy

  fill-db-with-examples:
    profiles: ["examples"]
    image: aiod_metadata_catalogue
    container_name: fill-db-with-examples
    environment:
      - MYSQL_ROOT_PASSWORD=${MYSQL_ROOT_PASSWORD}
      - KEYCLOAK_CLIENT_SECRET=$KEYCLOAK_CLIENT_SECRET
    volumes:
      - ${DATA_PATH}/connectors:/opt/connectors/data
      - ./src/config.override.toml:/app/config.override.toml:ro
    command: >
      /bin/bash -c "/opt/connectors/script/fill-examples.sh"
    depends_on:
      app:
        condition: service_healthy
  
  deletion:
    build:
      context: deletion
      dockerfile: Dockerfile
    image: aiod_deletion
    container_name: deletion
    volumes:
      - ${DATA_PATH}/deletion:/opt/deletion/data
      - ./src/config.override.toml:/app/config.override.toml:ro
    command: >
      /bin/bash -c "/opt/deletion/script/entry.sh"
    depends_on:
      app:
        condition: service_healthy

  huggingface-dataset-connector:
    profiles: ["huggingface-datasets"]
    image: aiod_metadata_catalogue
    container_name: huggingface-dataset-connector
    environment:
      - KEYCLOAK_CLIENT_SECRET=$KEYCLOAK_CLIENT_SECRET
    volumes:
      - ${DATA_PATH}/connectors:/opt/connectors/data
      - ./src/config.override.toml:/app/config.override.toml:ro
    command: >
      /bin/bash -c "/opt/connectors/script/datasets.sh"
    depends_on:
      app:
        condition: service_healthy

  openml-connector:
    profiles: ["openml"]
    build:
      context: connectors/openml
      dockerfile: Dockerfile
    image: aiod_openml_connector
    container_name: openml-connector
    environment:
      - KEYCLOAK_CLIENT_SECRET=$KEYCLOAK_CLIENT_SECRET
    volumes:
      - ${DATA_PATH}/connectors:/opt/connectors/data
      - ./src/config.override.toml:/app/config.override.toml:ro
    command: >
      /bin/bash -c "/opt/connectors/script/entry.sh"
    depends_on:
      app:
        condition: service_healthy

  zenodo-dataset-connector:
    profiles: ["zenodo-datasets"]
    build:
      context: connectors/zenodo
      dockerfile: Dockerfile
    image: aiod_zenodo_connector
    container_name: zenodo-dataset-connector
    environment:
      - KEYCLOAK_CLIENT_SECRET=$KEYCLOAK_CLIENT_SECRET
    volumes:
      - ${DATA_PATH}/connectors:/opt/connectors/data
      - ./src/config.override.toml:/app/config.override.toml:ro
    command: >
      /bin/bash -c "/opt/connectors/script/entry.sh"
    depends_on:
      app:
        condition: service_healthy

  aibuilder-connector:
    profiles: ["aibuilder"]
    build:
      context: connectors/aibuilder
      dockerfile: Dockerfile
    image: aiod_aibuilder_connector
    container_name: aibuilder-connector
    environment:
      - KEYCLOAK_CLIENT_SECRET=$KEYCLOAK_CLIENT_SECRET
      - AIBUILDER_API_TOKEN=$AIBUILDER_API_TOKEN
    volumes:
      - ./src:/app
      - ${DATA_PATH}/connectors:/opt/connectors/data
    command: >
      /bin/bash -c "/opt/connectors/script/entry.sh"
    depends_on:
      app:
        condition: service_healthy

  sqlserver:
    image: mysql:8.3.0
    container_name: sqlserver
    environment:
      - MYSQL_ROOT_PASSWORD=${MYSQL_ROOT_PASSWORD}
    volumes:
      - ${DATA_PATH}/mysql:/var/lib/mysql
    healthcheck:
      test: ["CMD", "mysqladmin", "-uroot", "-p$MYSQL_ROOT_PASSWORD", "ping", "-h", "localhost", "--protocol","tcp"]
      start_interval: 1s
      start_period: 10s
      interval: 5s
      timeout: 30s
      retries: 30

  keycloak:
    image: quay.io/keycloak/keycloak:24.0.4
    container_name: keycloak
    environment:
      - REDIRECT_URIS=$REDIRECT_URIS
      - POST_LOGOUT_REDIRECT_URIS=$POST_LOGOUT_REDIRECT_URIS
    ports:
      - ${AIOD_KEYCLOAK_PORT}:8080
    volumes:
     - ${DATA_PATH}/keycloak/data:/opt/keycloak/data
     - ${DATA_PATH}/keycloak/themes:/opt/keycloak/themes
    command: >
      start
      --proxy edge
      --hostname ${HOSTNAME}
      --http-relative-path=/aiod-auth
      --import-realm

  nginx:
    image: nginx:1.25.5
    container_name: nginx
    restart: unless-stopped
    volumes:
      - ./nginx:/etc/nginx/conf.d:ro
    ports:
      - ${AIOD_NGINX_PORT}:80
    depends_on:
      app:
        condition: service_healthy

  elasticsearch:
    image: docker.elastic.co/elasticsearch/elasticsearch:8.8.2
    container_name: elasticsearch
    environment:
      - ES_JAVA_OPTS=$ES_JAVA_OPTS
      - ELASTIC_USER=$ES_USER
      - ELASTIC_PASSWORD=$ES_PASSWORD
      - discovery.type=$ES_DISCOVERY_TYPE
    ports:
      - ${AIOD_ES_HTTP_PORT}:9200
      - ${AIOD_ES_TRANSPORT_PORT}:9300
    volumes:
      - type: bind
        source: ./es/elasticsearch.yml
        target: /usr/share/elasticsearch/config/elasticsearch.yml
        read_only: true
      - ${DATA_PATH}/elasticsearch:/usr/share/elasticsearch/data
    healthcheck:
      test: ["CMD-SHELL", "curl -u $ES_USER:$ES_PASSWORD --silent --fail localhost:9200/_cluster/health || exit 1"]
      interval: 5s
      timeout: 30s
      retries: 30
  
  es_logstash_setup:
    image: aiod_metadata_catalogue
    container_name:  es_logstash_setup
    environment:
      - MYSQL_ROOT_PASSWORD=$MYSQL_ROOT_PASSWORD
      - ES_USER=$ES_USER
      - ES_PASSWORD=$ES_PASSWORD
    volumes:
      - ./src/config.override.toml:/app/config.override.toml:ro
      - ./logstash:/logstash
    command: >
      /bin/bash -c "python setup/logstash_setup/generate_logstash_config_files.py &&
      python setup/es_setup/generate_elasticsearch_indices.py"
    restart: "no"
    depends_on:
      elasticsearch:
        condition: service_healthy

  logstash:
    build:
      context: logstash/
      dockerfile: Dockerfile
    image: aiod_logstash
    container_name: logstash
    environment:
      - LS_JAVA_OPTS=$LS_JAVA_OPTS
    ports:
      - ${AIOD_LOGSTASH_BEATS_PORT}:5044
      - ${AIOD_LOGSTASH_PORT}:5000/tcp
      - ${AIOD_LOGSTASH_PORT}:5000/udp
      - ${AIOD_LOGSTASH_API_PORT}:9600
    volumes:
      - ./logstash/config/config:/usr/share/logstash/config:ro
      - ./logstash/config/pipeline:/usr/share/logstash/pipeline:ro
      - ./logstash/config/sql:/usr/share/logstash/sql:ro
    depends_on:
      es_logstash_setup:
        condition: service_completed_successfully
