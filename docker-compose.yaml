  
version: '3.9'

services:
  app:
    build:
      context: ./
      dockerfile: Dockerfile
    image: aiod_metadata_catalogue
    container_name: apiserver
    env_file: .env
    environment:
      - KEYCLOAK_CLIENT_SECRET=$KEYCLOAK_CLIENT_SECRET
    ports:
      - 8000:8000
    volumes:
      - ./src:/app:ro
    command: >
      python main.py
      --rebuild-db only-if-empty
      --reload
    healthcheck:
      test: ["CMD", "python", "-c",  "import requests; requests.get('http://localhost:8000')"]
      start_interval: 1s
      start_period: 30s
      interval: 5s
      timeout: 120s
      retries: 24
    depends_on:
      sqlserver:
        condition: service_healthy

  fill-db-with-examples:
    profiles: ["examples"]
    image: aiod_metadata_catalogue
    container_name: fill-db-with-examples
    env_file: .env
    environment:
      - KEYCLOAK_CLIENT_SECRET=$KEYCLOAK_CLIENT_SECRET
    volumes:
      - ./src:/app:ro
      - ${DATA_PATH}/connectors:/opt/connectors/data
      - ./connectors:/opt/connectors/script:ro
    command: >
      /bin/bash -c "/opt/connectors/script/fill-examples.sh"
    depends_on:
      app:
        condition: service_healthy
  
  deletion:
    build:
      context: deletion
      dockerfile: Dockerfile
    image: aiod_deletion
    container_name: deletion
    env_file: .env
    volumes:
      - ./src:/app
      - ${DATA_PATH}/deletion:/opt/deletion/data
    command: >
      /bin/bash -c "/opt/deletion/script/entry.sh"
    depends_on:
      app:
        condition: service_healthy

  huggingface-dataset-connector:
    profiles: ["huggingface-datasets"]
    image: aiod_metadata_catalogue
    container_name: huggingface-dataset-connector
    env_file: .env
    environment:
      - KEYCLOAK_CLIENT_SECRET=$KEYCLOAK_CLIENT_SECRET
    volumes:
      - ./src:/app:ro
      - ${DATA_PATH}/connectors:/opt/connectors/data
      - ./connectors/huggingface/:/opt/connectors/script:ro
    command: >
      /bin/bash -c "/opt/connectors/script/datasets.sh"
    depends_on:
      app:
        condition: service_healthy

  openml-connector:
    profiles: ["openml"]
    build:
      context: connectors/openml
      dockerfile: Dockerfile
    image: aiod_openml_connector
    container_name: openml-connector
    env_file: .env
    environment:
      - KEYCLOAK_CLIENT_SECRET=$KEYCLOAK_CLIENT_SECRET
    volumes:
      - ./src:/app:ro
      - ${DATA_PATH}/connectors:/opt/connectors/data
      - ./connectors/openml/:/opt/connectors/script:ro
    command: >
      /bin/bash -c "/opt/connectors/script/entry.sh"
    depends_on:
      app:
        condition: service_healthy

  zenodo-dataset-connector:
    profiles: ["zenodo-datasets"]
    build:
      context: connectors/zenodo
      dockerfile: Dockerfile
    image: aiod_zenodo_connector
    container_name: zenodo-dataset-connector
    env_file: .env
    environment:
      - KEYCLOAK_CLIENT_SECRET=$KEYCLOAK_CLIENT_SECRET
    volumes:
      - ./src:/app
      - ${DATA_PATH}/connectors:/opt/connectors/data
      - ./connectors/zenodo/:/opt/connectors/script
    command: >
      /bin/bash -c "/opt/connectors/script/entry.sh"
    depends_on:
      app:
        condition: service_healthy

  sqlserver:
    image: mysql:8.3.0
    container_name: sqlserver
    env_file: .env
    environment:
      - MYSQL_ROOT_PASSWORD=${MYSQL_ROOT_PASSWORD}
    volumes:
      - ${DATA_PATH}/mysql:/var/lib/mysql
    healthcheck:
      test: ["CMD", "mysqladmin", "-uroot", "-p$MYSQL_ROOT_PASSWORD", "ping", "-h", "localhost", "--protocol","tcp"]
      start_interval: 1s
      start_period: 10s
      interval: 5s
      timeout: 30s
      retries: 30

  keycloak:
    image: quay.io/keycloak/keycloak:24.0.4
    container_name: keycloak
    env_file: .env
    environment:
      - REDIRECT_URIS=$REDIRECT_URIS
      - POST_LOGOUT_REDIRECT_URIS=$POST_LOGOUT_REDIRECT_URIS
    ports:
      - 8080:8080
    volumes:
     - ${DATA_PATH}/keycloak:/opt/keycloak/data
    command: >
      start
      --hostname-url http://${HOSTNAME}/aiod-auth
      --hostname-admin-url http://${HOSTNAME}/aiod-auth
      --http-relative-path=/aiod-auth
      --http-enabled=true
      --hostname-strict-https=false
      --import-realm

  nginx:
    image: nginx:1.25.5
    container_name: nginx
    restart: unless-stopped
    volumes:
      - ./nginx:/etc/nginx/conf.d:ro
    ports:
      - 80:80
    depends_on:
      app:
        condition: service_healthy

  elasticsearch:
    image: docker.elastic.co/elasticsearch/elasticsearch:8.8.2
    container_name: elasticsearch
    env_file: .env
    environment:
      - ES_JAVA_OPTS=$ES_JAVA_OPTS
      - ELASTIC_USER=$ES_USER
      - ELASTIC_PASSWORD=$ES_PASSWORD
      - discovery.type=$ES_DISCOVERY_TYPE
    ports:
      - 9200:9200
      - 9300:9300
    volumes:
      - type: bind
        source: ./es/elasticsearch.yml
        target: /usr/share/elasticsearch/config/elasticsearch.yml
        read_only: true
      - ${DATA_PATH}/elasticsearch:/usr/share/elasticsearch/data
    healthcheck:
      test: ["CMD-SHELL", "curl -u $ES_USER:$ES_PASSWORD --silent --fail localhost:9200/_cluster/health || exit 1"]
      interval: 5s
      timeout: 30s
      retries: 30
  
  es_logstash_setup:
    image: aiod_metadata_catalogue
    container_name:  es_logstash_setup
    env_file: .env
    environment:
      - MYSQL_ROOT_PASSWORD=$MYSQL_ROOT_PASSWORD
      - ES_USER=$ES_USER
      - ES_PASSWORD=$ES_PASSWORD
    volumes:
      - ./src:/app
      - ./logstash:/logstash
    command: >
      /bin/bash -c "python setup/logstash_setup/generate_logstash_config_files.py &&
      python setup/es_setup/generate_elasticsearch_indices.py"
    restart: "no"
    depends_on:
      elasticsearch:
        condition: service_healthy

  logstash:
    build:
      context: logstash/
      dockerfile: Dockerfile
    image: aiod_logstash
    container_name: logstash
    env_file: .env
    environment:
      - LS_JAVA_OPTS=$LS_JAVA_OPTS
    ports:
      - 5044:5044
      - 5000:5000/tcp
      - 5000:5000/udp
      - 9600:9600
    volumes:
      - ./logstash/config/config:/usr/share/logstash/config:ro
      - ./logstash/config/pipeline:/usr/share/logstash/pipeline:ro
      - ./logstash/config/sql:/usr/share/logstash/sql:ro
    depends_on:
      es_logstash_setup:
        condition: service_completed_successfully
